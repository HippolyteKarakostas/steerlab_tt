{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f50f2b-9fb4-4e86-93b4-8198ab1d0306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16b8a2fd-7310-412d-bc80-b1abfddc6bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import unicodedata\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from typing import Iterable\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08411095-5345-4682-9f99-9563ae5c9a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.gutenberg.org/cache/epub/feeds/pg_catalog.csv\"\n",
    "r = requests.get(url)\n",
    "with open(\"pg_catalog.csv\", \"wb\") as f:\n",
    "    f.write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ffded44-139a-4d38-a1f0-cdd45dc61f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text#</th>\n",
       "      <th>Type</th>\n",
       "      <th>Issued</th>\n",
       "      <th>Title</th>\n",
       "      <th>Language</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Subjects</th>\n",
       "      <th>LoCC</th>\n",
       "      <th>Bookshelves</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Text</td>\n",
       "      <td>1971-12-01</td>\n",
       "      <td>The Declaration of Independence of the United ...</td>\n",
       "      <td>en</td>\n",
       "      <td>Jefferson, Thomas, 1743-1826</td>\n",
       "      <td>United States -- History -- Revolution, 1775-1...</td>\n",
       "      <td>E201; JK</td>\n",
       "      <td>Politics; American Revolutionary War; United S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Text</td>\n",
       "      <td>1972-12-01</td>\n",
       "      <td>The United States Bill of Rights\\r\\nThe Ten Or...</td>\n",
       "      <td>en</td>\n",
       "      <td>United States</td>\n",
       "      <td>Civil rights -- United States -- Sources; Unit...</td>\n",
       "      <td>JK; KF</td>\n",
       "      <td>Politics; American Revolutionary War; United S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Text</td>\n",
       "      <td>1973-11-01</td>\n",
       "      <td>John F. Kennedy's Inaugural Address</td>\n",
       "      <td>en</td>\n",
       "      <td>Kennedy, John F. (John Fitzgerald), 1917-1963</td>\n",
       "      <td>United States -- Foreign relations -- 1961-196...</td>\n",
       "      <td>E838</td>\n",
       "      <td>Category: Essays, Letters &amp; Speeches; Category...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Text</td>\n",
       "      <td>1973-11-01</td>\n",
       "      <td>Lincoln's Gettysburg Address\\r\\nGiven November...</td>\n",
       "      <td>en</td>\n",
       "      <td>Lincoln, Abraham, 1809-1865</td>\n",
       "      <td>Consecration of cemeteries -- Pennsylvania -- ...</td>\n",
       "      <td>E456</td>\n",
       "      <td>US Civil War; Category: Essays, Letters &amp; Spee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Text</td>\n",
       "      <td>1975-12-01</td>\n",
       "      <td>The United States Constitution</td>\n",
       "      <td>en</td>\n",
       "      <td>United States</td>\n",
       "      <td>United States -- Politics and government -- 17...</td>\n",
       "      <td>JK; KF</td>\n",
       "      <td>United States; Politics; American Revolutionar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Text#  Type      Issued                                              Title  \\\n",
       "0      1  Text  1971-12-01  The Declaration of Independence of the United ...   \n",
       "1      2  Text  1972-12-01  The United States Bill of Rights\\r\\nThe Ten Or...   \n",
       "2      3  Text  1973-11-01                John F. Kennedy's Inaugural Address   \n",
       "3      4  Text  1973-11-01  Lincoln's Gettysburg Address\\r\\nGiven November...   \n",
       "4      5  Text  1975-12-01                     The United States Constitution   \n",
       "\n",
       "  Language                                        Authors  \\\n",
       "0       en                   Jefferson, Thomas, 1743-1826   \n",
       "1       en                                  United States   \n",
       "2       en  Kennedy, John F. (John Fitzgerald), 1917-1963   \n",
       "3       en                    Lincoln, Abraham, 1809-1865   \n",
       "4       en                                  United States   \n",
       "\n",
       "                                            Subjects      LoCC  \\\n",
       "0  United States -- History -- Revolution, 1775-1...  E201; JK   \n",
       "1  Civil rights -- United States -- Sources; Unit...    JK; KF   \n",
       "2  United States -- Foreign relations -- 1961-196...      E838   \n",
       "3  Consecration of cemeteries -- Pennsylvania -- ...      E456   \n",
       "4  United States -- Politics and government -- 17...    JK; KF   \n",
       "\n",
       "                                         Bookshelves  \n",
       "0  Politics; American Revolutionary War; United S...  \n",
       "1  Politics; American Revolutionary War; United S...  \n",
       "2  Category: Essays, Letters & Speeches; Category...  \n",
       "3  US Civil War; Category: Essays, Letters & Spee...  \n",
       "4  United States; Politics; American Revolutionar...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"pg_catalog.csv\").fillna(\"\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8d12e30-dbf7-49d1-8945-0c242a8929e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# caractères à garder tels quels\n",
    "_KEEP = set(\"-'\")  # utile pour noms composés et titres\n",
    "_TRANS_TABLE = str.maketrans({c: \" \" for c in string.punctuation if c not in _KEEP})\n",
    "\n",
    "\n",
    "def remove_accents(s: str) -> str:\n",
    "    \"\"\"\n",
    "    La normalisation NFKD (Normalization Form KD = Compatibility Decomposition) décompose les caractères en leur forme de base + diacritiques.\n",
    "    Par exemple:\n",
    "        \"e\" --> \"e\"\n",
    "        \"è\" --> \"e`\"\n",
    "    La fonction 'unicodedata.normalize' opère cette séparation\n",
    "    La fonction 'unicodedata.combining' remplace chaque caractère par un entier différent de 0 si c'est un accent, 0 si c'est un accent.\n",
    "    \"\"\"\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    return \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
    "\n",
    "def base_normalize(s: str) -> str:\n",
    "    if not s: \n",
    "        return \"\"\n",
    "    # suppression de la casse\n",
    "    s = s.casefold()\n",
    "    s = remove_accents(s)\n",
    "    s = s.translate(_TRANS_TABLE)          # ponctuation → espaces (sauf - et ')\n",
    "    # compacter les espaces multiples et supprimer les espaces en début et fin de chaine\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def normalize_title(title: str) -> dict:\n",
    "    # À enrichir si on veut aller plus loin, par exemple supprimer les articles\n",
    "    norm = base_normalize(title)\n",
    "    return norm\n",
    "\n",
    "def normalize_authors(authors: str) -> list:\n",
    "    if not authors:\n",
    "        return []\n",
    "    return sorted(set(normalize_author(author) for author in authors.split(\";\")))\n",
    "\n",
    "def check_initials(potential_initials: str, potential_full_name: str) -> bool:\n",
    "    initials = [initial for initial in potential_initials.split(\" \") if initial]\n",
    "    names = [name for name in potential_full_name.split(\" \") if name]\n",
    "    if len(initials) == len(names):\n",
    "        for initial, name in zip(initials, names):\n",
    "            if initial[0] != name[0]:\n",
    "                return False\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def remove_all_potential_initials(s: str) -> str:\n",
    "    all_potential_initials = re.findall(r\"((?:(?:\\w+ )|(?:\\w\\. ))+)\\(((?:\\w+ ?)+?)\\)\", s)\n",
    "    if all_potential_initials:\n",
    "        for (potential_initials, potential_full_name) in all_potential_initials:\n",
    "            if check_initials(potential_initials, potential_full_name):\n",
    "                s = s.replace(potential_initials, potential_full_name)\n",
    "    return s\n",
    "            \n",
    "def normalize_author(author: str) -> str:\n",
    "    \"\"\"\n",
    "    Nettoie les auteurs pour l'autocomplete:\n",
    "      - supprime dates (chiffres), contenus entre ()/[]/{}\n",
    "      - compresse initiales 'J. K.' → 'jk'\n",
    "      - garde - et ' pour les noms composés (dumas, o'connor)\n",
    "    \"\"\"\n",
    "    if not author: \n",
    "        return \"\"\n",
    "    s = author\n",
    "    s = remove_all_potential_initials(s)\n",
    "    # retirer parenthèses / crochets / accolades et leur contenu\n",
    "    s = re.sub(r\"[\\(\\[\\{].*?[\\)\\]\\}]\", \" \", s)\n",
    "    # retirer chiffres (dates, numéros)\n",
    "    s = re.sub(r\"\\d+\", \" \", s)\n",
    "    # normalisation de base (accents, casse, ponctuation)\n",
    "    s = base_normalize(s)\n",
    "    # compacter initiales restantes qui n'ont pas pu être supprimées: \"j. k.\" -> \"jk\"; \"j k\" -> \"jk\"\n",
    "    s = re.sub(r\"\\b([a-z])\\b(?:\\s+|\\.)\", r\"\\1\", s)  # colle les lettres isolées\n",
    "    # Retirer les tirets résiduels en début et fin de chaine\n",
    "    s = re.sub(r\"^-*\", \"\", s)\n",
    "    s = re.sub(r\"-*$\", \"\", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "df[\"title_norm\"] = df[\"Title\"].apply(lambda s: normalize_title(s))\n",
    "df[\"auths_norm\"] = df[\"Authors\"].apply(lambda s: normalize_authors(s))\n",
    "df[\"auth_norm\"] = df[\"auths_norm\"].apply(lambda s: \"; \".join(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9a7e47d0-514d-483f-a363-3a4d44a80b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth_norm_all = df[\"auth_norm\"].drop_duplicates().sort_values().to_list()\n",
    "title_norm_all = df[\"title_norm\"].sort_values().to_list()\n",
    "real_norm_title_matching = df.set_index(\"title_norm\")[\"Title\"].to_dict()\n",
    "real_norm_auth_matching = df.set_index(\"auth_norm\")[\"Authors\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d28884bd-1488-4a4b-a7f4-bef5b85ec339",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_all_3grams_from_list(L: list[str]) -> defaultdict[str, set[str]]:\n",
    "    trigrams = defaultdict(set)\n",
    "    for elem in L:\n",
    "        for i in range(max(0, 1 + len(elem) - 3)):\n",
    "            trigrams[elem[i: i + 3]].add(elem)\n",
    "    return trigrams\n",
    "\n",
    "auth_3grams = match_all_3grams_from_list(auth_norm_all)\n",
    "title_3grams = match_all_3grams_from_list(title_norm_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f45eb00f-7907-494b-85e0-662bde7a886d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf_score(trigram, is_title=True):\n",
    "    if is_title:\n",
    "        corpus = title_norm_all\n",
    "        subcorpus = title_3grams.get(trigram, set())\n",
    "    else:\n",
    "        corpus = auth_norm_all\n",
    "        subcorpus = auth_3grams.get(trigram, set())\n",
    "    return 1 + np.log((1 + len(corpus)) / (1 + len(subcorpus)))\n",
    "\n",
    "title_idfs = {trigram: idf_score(trigram, is_title=True) for trigram in title_3grams}\n",
    "auth_idfs = {trigram: idf_score(trigram, is_title=False) for trigram in auth_3grams}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1a74de3c-13d4-4c93-872c-245d05a04f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bon', 'onj', 'njo', 'jou', 'our']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_all_3grams_from_string(s: str) -> list[str]:\n",
    "    return [s[i: i + 3] for i in range(max(0, 1 + len(s) - 3))]\n",
    "get_all_3grams_from_string(\"bonjour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d2b52f6d-ba49-4c40-9e00-832bbbdd38ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_index_matching = {title: index for index, title in enumerate(title_norm_all)}\n",
    "title_trigram_index_matching = {trigram: index for index, trigram in enumerate(title_3grams)}\n",
    "\n",
    "auth_index_matching = {auth: index for index, auth in enumerate(auth_norm_all)}\n",
    "auth_trigram_index_matching = {trigram: index for index, trigram in enumerate(auth_3grams)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f7d38fd7-1cf9-403c-93e7-35954f5dea63",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, rows, cols = [], [], []\n",
    "for title, i in title_index_matching.items():\n",
    "    trigrams = get_all_3grams_from_string(title)\n",
    "    for trigram in trigrams:\n",
    "        j = title_trigram_index_matching[trigram]\n",
    "        data.append(title_idfs[trigram])\n",
    "        rows.append(i)\n",
    "        cols.append(j)\n",
    "title_weights = csr_matrix((data, (rows, cols)), shape=(len(title_norm_all), len(title_3grams)), dtype=\"float32\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "25e4c8d1-2830-4433-a37d-c41edafb586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, rows, cols = [], [], []\n",
    "for auth, i in auth_index_matching.items():\n",
    "    trigrams = get_all_3grams_from_string(auth)\n",
    "    for trigram in trigrams:\n",
    "        j = auth_trigram_index_matching[trigram]\n",
    "        data.append(auth_idfs[trigram])\n",
    "        rows.append(i)\n",
    "        cols.append(j)\n",
    "auth_weights = csr_matrix((data, (rows, cols)), shape=(len(auth_norm_all), len(auth_3grams)), dtype=\"float32\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3c1f2f0b-c96e-4721-bc8c-2800b736c02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(L: Iterable) -> float:\n",
    "    return np.sqrt(sum(x ** 2 for x in L))\n",
    "\n",
    "def get_all_posible_choices(trigrams, is_title=True):\n",
    "    if not trigrams:\n",
    "        return set()\n",
    "    if is_title:\n",
    "        return set.intersection(*(title_3grams.get(trigram, set()) for trigram in trigrams))\n",
    "    return set.intersection(*(auth_3grams.get(trigram, set()) for trigram in trigrams))\n",
    "\n",
    "def get_most_relevant_choice(q, is_title=True):\n",
    "    if is_title:\n",
    "        q = normalize_title(q)\n",
    "    else:\n",
    "        q = \"; \".join(normalize_authors(q))\n",
    "    trigrams = get_all_3grams_from_string(q)\n",
    "    posible_choices = get_all_posible_choices(trigrams, is_title=is_title)\n",
    "    if is_title:\n",
    "        idfs = title_idfs\n",
    "        weights = title_weights\n",
    "        indexes = title_index_matching\n",
    "    else:\n",
    "        idfs = auth_idfs\n",
    "        weights = auth_weights\n",
    "        indexes = auth_index_matching\n",
    "    w_q = np.array([\n",
    "        idfs[trigram] if trigram in trigrams else 0\n",
    "        for trigram in idfs\n",
    "    ])\n",
    "    best_score = 0\n",
    "    best_choice = \"\"\n",
    "    for choice in posible_choices:\n",
    "        w_d = weights[indexes[choice]]\n",
    "        score = float(w_d @ w_q) / norm(w_q) / np.sqrt(w_d.multiply(w_d).sum())\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_choice = choice\n",
    "    if is_title:\n",
    "        return real_norm_title_matching.get(best_choice, \"\")\n",
    "    return real_norm_auth_matching.get(best_choice, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "612afabb-48f2-42fe-8b04-e0e198ae4628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43028/1420115130.py:34: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  score = float(w_d @ w_q) / norm(w_q) / np.sqrt(w_d.multiply(w_d).sum())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Dostoyevsky, Fyodor, 1821-1881'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_most_relevant_choice(\"dosto\", is_title=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6523d5-0156-4ea2-afb6-583fa4f0cc4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85065c98-487f-4412-8b65-8429bd1d833a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bfb932-c4e8-4785-ae19-a13d296be6ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb5adeb-a95e-4d9a-b40b-f7c644ccea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sublist_from_indexes(L, indexes):\n",
    "    return [x for i, x in enumerate(L) if int(indexes[i])]\n",
    "\n",
    "def get_all_indexes(L):\n",
    "    N = len(L)\n",
    "    return [\n",
    "        list(format(k, f\"0{N}b\"))\n",
    "        for k in range(1, 2**N)\n",
    "    ]\n",
    "\n",
    "def get_all_sublists(L):\n",
    "    return [\n",
    "        get_sublist_from_indexes(L, indexes)\n",
    "        for indexes in get_all_indexes(L)\n",
    "    ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
